{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import numpy as np\n",
    "import cv2.cv2 as cv2\n",
    "\n",
    "def data():\n",
    "    lfw_people = fetch_lfw_people(\n",
    "        min_faces_per_person=4,\n",
    "        color=True,\n",
    "        slice_=(slice(0, 250, None), slice(0, 250, None)),\n",
    "    )\n",
    "\n",
    "    # The original images are 250 x 250 pixels,\n",
    "    # but the default slice and resize arguments reduce them to 62 x 47 pixels.\n",
    "\n",
    "    # introspect the images arrays to find the shapes\n",
    "    n_samples, h, w, pixel = lfw_people.images.shape\n",
    "\n",
    "    X = lfw_people.images\n",
    "\n",
    "    # the label to predict is the id of the person\n",
    "    y = lfw_people.target\n",
    "    target_names = lfw_people.target_names\n",
    "    n_classes = target_names.shape[0]\n",
    "\n",
    "    print(\"Total dataset size:\")\n",
    "    print(\"n_samples: %d\" % n_samples)\n",
    "    # print(\"n_features: %d\" % n_features)\n",
    "    print(\"n_classes: %d\" % n_classes)\n",
    "    print(\"Image size: %dx%d\" % (h, w))\n",
    "\n",
    "    # split into a training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.15, shuffle=True \n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, n_classes\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, n_classes = data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "m_E7KM9DzStC",
    "outputId": "7deff4e9-e58a-48ee-a290-95a9ae4c7e3c"
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "img_height, img_width = X_train[0].shape[0], X_train[0].shape[1]\n",
    "num_classes = n_classes\n",
    "epochs=30\n",
    "batch_size=32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    ")\n",
    "model.add(Dense(num_classes, activation=\"softmax\", name=\"softmax1\"))\n",
    "\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", restore_best_weights=True, patience=10, verbose=0, mode=\"min\"\n",
    ")\n",
    "log = CSVLogger(\"drive/My Drive/Colab Notebooks/Resnet_Face_Detection/resnet_logs.csv\")\n",
    "lr_reduce = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "\tfill_mode=\"nearest\",\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1)\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_test, y_test), callbacks=[earlyStopping, log, lr_reduce])\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_test, y_test),callbacks=[earlyStopping, log, lr_reduce],\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)\n",
    "\n",
    "preds = model.evaluate(X_test, y_test)\n",
    "print(\"Loss = \" + str(preds[0]))\n",
    "print(\"Test Accuracy = \" + str(preds[1]))\n",
    "model.summary()\n",
    "\n",
    "# model.save(\"drive/My Drive/Colab Notebooks/Resnet_Face_Detection/model.h5\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
