# -*- coding: utf-8 -*-
"""classifier_gcolab.ipynb

Automatically generated by Colaboratory.


"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.datasets import fetch_lfw_people
import numpy as np
import cv2.cv2 as cv2

def data():
    lfw_people = fetch_lfw_people(
        data_home="drive/My Drive/Colab Notebooks/Resnet_Face_Detection/scikit_learn_data",
        min_faces_per_person=14,
        color=True,
        slice_=(slice(0, 250, None), slice(0, 250, None)),
    )

    # The original images are 250 x 250 pixels,
    # but the default slice and resize arguments reduce them to 62 x 47 pixels.

    # introspect the images arrays to find the shapes
    n_samples, h, w, pixel = lfw_people.images.shape

    X = lfw_people.images

    # the label to predict is the id of the person
    y = lfw_people.target
    target_names = lfw_people.target_names
    n_classes = target_names.shape[0]

    print("Total dataset size:")
    print("n_samples: %d" % n_samples)
    # print("n_features: %d" % n_features)
    print("n_classes: %d" % n_classes)
    print("Image size: %dx%d" % (h, w))

    # split into a training and testing set
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.15, shuffle=True 
    )

    return X_train, X_test, y_train, y_test, n_classes


X_train, X_test, y_train, y_test, n_classes = data()

from keras.applications.resnet50 import ResNet50#, preprocess_input
# from keras import optimizers
from keras.models import Sequential#, Model, load_model
from keras.layers import (
    Dense,
)
    # Dropout,
    # Flatten,
    # GlobalAveragePooling2D,
    # BatchNormalization,
from keras.optimizers import SGD, Adam
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

img_height, img_width = X_train[0].shape[0], X_train[0].shape[1]
num_classes = n_classes
epochs=20
batch_size=32

model = Sequential()

model.add(
    ResNet50(
        include_top=False,
        weights="imagenet",
        pooling="avg",
        input_shape=(img_height, img_width, 3)
    )
)
model.add(Dense(num_classes, activation="softmax", name="softmax1"))

earlyStopping = EarlyStopping(
    monitor="val_loss", restore_best_weights=True, patience=4, verbose=0, mode="min"
)
# log = CSVLogger("drive/My Drive/Colab Notebooks/Resnet_Face_Detection/resnet_logs.csv")
lr_reduce = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

datagen = ImageDataGenerator(
    horizontal_flip=True,
   	fill_mode="nearest",
    shear_range=0.1,
    zoom_range=0.1
)

# model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_test, y_test), callbacks=[earlyStopping, log, lr_reduce])
model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_test, y_test),callbacks=[earlyStopping, lr_reduce],
                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)


model.save("drive/My Drive/Colab Notebooks/Resnet_Face_Detection/model.h5", overwrite=True)

preds = model.evaluate(X_test, y_test)
print("\nLoss = " + str(preds[0]))
print("Test Accuracy = " + str(100*preds[1]))
model.summary()
