{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "classifier_gcolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SZTY-m0IyXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c34454d-61cd-4f9c-b17f-4f28fe8afaa3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci71kR_HeL0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "d1f3f227-feaf-4fe3-e940-4877207e2016"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "import numpy as np\n",
        "import cv2.cv2 as cv2\n",
        "\n",
        "def data():\n",
        "    lfw_people = fetch_lfw_people(\n",
        "        data_home=\"drive/My Drive/Colab Notebooks/Resnet_Face_Detection/scikit_learn_data\",\n",
        "        min_faces_per_person=14,\n",
        "        color=True,\n",
        "        slice_=(slice(0, 250, None), slice(0, 250, None)),\n",
        "    )\n",
        "\n",
        "    # The original images are 250 x 250 pixels,\n",
        "    # but the default slice and resize arguments reduce them to 62 x 47 pixels.\n",
        "\n",
        "    # introspect the images arrays to find the shapes\n",
        "    n_samples, h, w, pixel = lfw_people.images.shape\n",
        "\n",
        "    X = lfw_people.images\n",
        "\n",
        "    # the label to predict is the id of the person\n",
        "    y = lfw_people.target\n",
        "    target_names = lfw_people.target_names\n",
        "    n_classes = target_names.shape[0]\n",
        "\n",
        "    print(\"Total dataset size:\")\n",
        "    print(\"n_samples: %d\" % n_samples)\n",
        "    # print(\"n_features: %d\" % n_features)\n",
        "    print(\"n_classes: %d\" % n_classes)\n",
        "    print(\"Image size: %dx%d\" % (h, w))\n",
        "\n",
        "    # split into a training and testing set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.15, shuffle=True \n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, n_classes\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, n_classes = data()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total dataset size:\n",
            "n_samples: 3735\n",
            "n_classes: 106\n",
            "Image size: 125x125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_E7KM9DzStC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "9cf0ac97-a36c-42af-daea-6678c858440a"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50#, preprocess_input\n",
        "# from keras import optimizers\n",
        "from keras.models import Sequential#, Model, load_model\n",
        "from keras.layers import (\n",
        "    Dense,\n",
        ")\n",
        "    # Dropout,\n",
        "    # Flatten,\n",
        "    # GlobalAveragePooling2D,\n",
        "    # BatchNormalization,\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "img_height, img_width = X_train[0].shape[0], X_train[0].shape[1]\n",
        "num_classes = n_classes\n",
        "epochs=20\n",
        "batch_size=32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    ResNet50(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(img_height, img_width, 3)\n",
        "    )\n",
        ")\n",
        "model.add(Dense(num_classes, activation=\"softmax\", name=\"softmax1\"))\n",
        "\n",
        "earlyStopping = EarlyStopping(\n",
        "    monitor=\"val_loss\", restore_best_weights=True, patience=4, verbose=0, mode=\"min\"\n",
        ")\n",
        "# log = CSVLogger(\"drive/My Drive/Colab Notebooks/Resnet_Face_Detection/resnet_logs.csv\")\n",
        "lr_reduce = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "   \tfill_mode=\"nearest\",\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "# model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_test, y_test), callbacks=[earlyStopping, log, lr_reduce])\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_test, y_test),callbacks=[earlyStopping, lr_reduce],\n",
        "                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)\n",
        "\n",
        "\n",
        "model.save(\"drive/My Drive/Colab Notebooks/Resnet_Face_Detection/model.h5\", overwrite=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/99 [==============================] - 77s 774ms/step - loss: 3.2220 - accuracy: 0.3166 - val_loss: 5.0284 - val_accuracy: 0.0802\n",
            "Epoch 2/20\n",
            "100/99 [==============================] - 58s 580ms/step - loss: 1.5064 - accuracy: 0.6084 - val_loss: 4.2232 - val_accuracy: 0.1159\n",
            "Epoch 3/20\n",
            "100/99 [==============================] - 58s 579ms/step - loss: 0.8534 - accuracy: 0.7637 - val_loss: 3.2656 - val_accuracy: 0.3387\n",
            "Epoch 4/20\n",
            "100/99 [==============================] - 58s 581ms/step - loss: 0.5310 - accuracy: 0.8459 - val_loss: 2.5734 - val_accuracy: 0.4189\n",
            "Epoch 5/20\n",
            "100/99 [==============================] - 58s 580ms/step - loss: 0.3991 - accuracy: 0.8891 - val_loss: 2.0622 - val_accuracy: 0.5152\n",
            "Epoch 6/20\n",
            "100/99 [==============================] - 58s 580ms/step - loss: 0.2895 - accuracy: 0.9178 - val_loss: 2.9749 - val_accuracy: 0.3672\n",
            "Epoch 7/20\n",
            "100/99 [==============================] - 58s 580ms/step - loss: 0.1848 - accuracy: 0.9502 - val_loss: 1.5488 - val_accuracy: 0.6364\n",
            "Epoch 8/20\n",
            "100/99 [==============================] - 58s 578ms/step - loss: 0.1464 - accuracy: 0.9559 - val_loss: 1.8323 - val_accuracy: 0.5865\n",
            "Epoch 9/20\n",
            "100/99 [==============================] - 58s 577ms/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 1.3412 - val_accuracy: 0.6560\n",
            "Epoch 10/20\n",
            "100/99 [==============================] - 60s 601ms/step - loss: 0.0903 - accuracy: 0.9701 - val_loss: 1.8750 - val_accuracy: 0.5882\n",
            "Epoch 11/20\n",
            "100/99 [==============================] - 58s 578ms/step - loss: 0.1476 - accuracy: 0.9587 - val_loss: 2.7851 - val_accuracy: 0.4973\n",
            "Epoch 12/20\n",
            "100/99 [==============================] - 58s 578ms/step - loss: 0.1735 - accuracy: 0.9502 - val_loss: 2.2545 - val_accuracy: 0.5561\n",
            "Epoch 13/20\n",
            "100/99 [==============================] - 58s 581ms/step - loss: 0.0992 - accuracy: 0.9691 - val_loss: 1.5970 - val_accuracy: 0.6631\n",
            "Epoch 14/20\n",
            "100/99 [==============================] - 58s 579ms/step - loss: 0.0947 - accuracy: 0.9748 - val_loss: 1.6749 - val_accuracy: 0.6185\n",
            "Epoch 15/20\n",
            "100/99 [==============================] - 58s 579ms/step - loss: 0.0421 - accuracy: 0.9905 - val_loss: 0.5013 - val_accuracy: 0.8627\n",
            "Epoch 16/20\n",
            "100/99 [==============================] - 58s 578ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.4397 - val_accuracy: 0.8895\n",
            "Epoch 17/20\n",
            "100/99 [==============================] - 58s 578ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.4041 - val_accuracy: 0.9037\n",
            "Epoch 18/20\n",
            "100/99 [==============================] - 58s 577ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9109\n",
            "Epoch 19/20\n",
            "100/99 [==============================] - 58s 579ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.4896 - val_accuracy: 0.8663\n",
            "Epoch 20/20\n",
            "100/99 [==============================] - 58s 580ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.4580 - val_accuracy: 0.8841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbYP8mEdL_2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "ff55c15f-15f0-45a0-f8fa-7d24ae663981"
      },
      "source": [
        "preds = model.evaluate(X_test, y_test)\n",
        "print(\"\\nLoss = \" + str(preds[0]))\n",
        "print(\"Test Accuracy = \" + str(100*preds[1]))\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "561/561 [==============================] - 3s 5ms/step\n",
            "\n",
            "Loss = 0.4579507594865061\n",
            "Test Accuracy = 88.41354846954346\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "softmax1 (Dense)             (None, 106)               217194    \n",
            "=================================================================\n",
            "Total params: 23,804,906\n",
            "Trainable params: 23,751,786\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}